{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5693e56a-8530-4606-ac77-ebc3cfac8bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Required librarie imported successfully\n",
      "Step 2: Created DataFrame successfully\n",
      "Step 3: Feature Engineering Done successfully on Weekend, Revenue\n",
      "Step 4: Added Returning_Visitor column successfully\n",
      "Step 5: Applied one hot encoding successfully on Month column\n",
      "Step 6: Checking correlation done successfully\n",
      "Step 7: Prepairing features as X and target as y done successfully\n",
      "Step 8: Splitting data X_train, X_test, y_train & y_test done successfully\n",
      "Step 9: model_pipeline fcuntion created done successfully\n",
      "Step 10: select_model fcuntion created done successfully\n",
      "Step 11: Accessing select_model function done successfully\n",
      "\n",
      "Step 12: model_pipeline run successfully on RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prasad Shree\\AppData\\Local\\Temp\\ipykernel_15548\\958294206.py:295: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_models = pd.concat([df_models, pd.DataFrame([row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 12: model_pipeline run successfully on DecisionTreeClassifier\n",
      "\n",
      "Step 12: model_pipeline run successfully on KNeighborsClassifier\n",
      "\n",
      "Step 12: model_pipeline run successfully on RidgeClassifier\n",
      "\n",
      "Step 12: model_pipeline run successfully on BernoulliNB\n",
      "\n",
      "Step 12: model_pipeline run successfully on SVC\n",
      "Step 13: Accessing select_model function done successfully\n",
      "                    model run_time   roc_auc\n",
      "0  RandomForestClassifier     0.62  0.886387\n",
      "5                     SVC     0.58  0.885963\n",
      "4             BernoulliNB     0.01  0.857851\n",
      "3         RidgeClassifier     0.01  0.855441\n",
      "2    KNeighborsClassifier     0.01  0.840505\n",
      "1  DecisionTreeClassifier     0.02  0.733311\n",
      "Step 14: Accessing select_model function done successfully\n",
      "Step 15: Results predicted successfully\n",
      "[0 0 0 ... 0 0 0]\n",
      "Step 16: ROC and AOC scores\n",
      "ROC/AUC: 0.7772768502330849\n",
      "Accuracy: 0.8780751554474182\n",
      "F1 score: 0.6330349877949553\n",
      "Step 17: classification report generated successfully\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      3077\n",
      "           1       0.64      0.63      0.63       622\n",
      "\n",
      "    accuracy                           0.88      3699\n",
      "   macro avg       0.78      0.78      0.78      3699\n",
      "weighted avg       0.88      0.88      0.88      3699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pip install imblearn\n",
    "print(\"Step 1: Required librarie imported successfully\")\n",
    "\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "\n",
    "####################\n",
    "# To ignore warning#\n",
    "####################\n",
    "\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "\n",
    "################################################\n",
    "# Loading online_shoppers_intention.csv dataset#\n",
    "################################################\n",
    "\n",
    "print(\"Step 2: Created DataFrame successfully\")\n",
    "\n",
    "df = pd.read_csv(\"A:/Csv_files/online_shoppers_intention/online_shoppers_intention.csv\")\n",
    "\n",
    "\n",
    "\n",
    "######################\n",
    "# Feature Engineering#\n",
    "######################\n",
    "\n",
    "print(\"Step 3: Feature Engineering Done successfully on Weekend, Revenue\")\n",
    "\n",
    "df['Weekend'] = df['Weekend'].replace((True, False), (1, 0))\n",
    "df['Revenue'] = df['Revenue'].replace((True, False), (1, 0))\n",
    "\n",
    "condition = df['VisitorType']=='Returning_Visitor'\n",
    "\n",
    "\n",
    "#################################\n",
    "# Added Returning_Visitor column#\n",
    "#################################\n",
    "\n",
    "print(\"Step 4: Added Returning_Visitor column successfully\")\n",
    "\n",
    "df['Returning_Visitor'] = np.where(condition, 1, 0)\n",
    "\n",
    "df = df.drop(columns=['VisitorType'])\n",
    "\n",
    "\n",
    "############################################\n",
    "# Applying One Hot Encoding on Month column#\n",
    "############################################\n",
    "\n",
    "print(\"Step 5: Applied one hot encoding successfully on Month column\")\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "df['Month'] = ordinal_encoder.fit_transform(df[['Month']])\n",
    "\n",
    "\n",
    "#########################################\n",
    "# Checking correlation on Revenue column#\n",
    "#########################################\n",
    "\n",
    "print(\"Step 6: Checking correlation done successfully\")\n",
    "\n",
    "result = df[df.columns[1:]].corr()['Revenue']\t\t\t\t\t\t\n",
    "result1 = result.sort_values(ascending=False)\n",
    "\n",
    "\n",
    "###########################################\n",
    "# Prepairing Features as X and target as y#\n",
    "###########################################\n",
    "\n",
    "print(\"Step 7: Prepairing features as X and target as y done successfully\")\n",
    "\n",
    "X = df.drop(['Revenue'], axis=1)\n",
    "y = df['Revenue']\n",
    "\n",
    "\n",
    "\n",
    "####################################\n",
    "# Prepairing Train and Test Dataset#\n",
    "####################################\n",
    "\n",
    "print(\"Step 8: Splitting data X_train, X_test, y_train & y_test done successfully\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 0)\n",
    "\n",
    "\n",
    "#################\n",
    "# Model Pipeline#\n",
    "#################\n",
    "\n",
    "print(\"Step 9: model_pipeline fcuntion created done successfully\")\n",
    "\n",
    "def model_pipeline(X, model):  \n",
    "    n_c = X.select_dtypes(exclude=['object']).columns.values.tolist()\n",
    "    c_c = X.select_dtypes(include=['object']).columns.values.tolist()\n",
    "\n",
    "    numeric_columns = n_c\n",
    "    categorical_columns = c_c\n",
    "\n",
    "    numeric_pipeline = SimpleImputer(strategy = 'constant')\n",
    "\n",
    "    categorical_pipeline = OneHotEncoder(handle_unknown = 'ignore')\n",
    "\n",
    "    a = ('numeric', numeric_pipeline, numeric_columns)\n",
    "    b = ('categorical', categorical_pipeline, categorical_columns)\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "\n",
    "    transformers = [a, b], \n",
    "    remainder = 'passthrough'\n",
    "\n",
    "    )\n",
    "\n",
    "    c = ('preprocessor', preprocessor)\n",
    "    d = ('smote', SMOTE(random_state = 1))\n",
    "    e = ('scaler', MinMaxScaler())\n",
    "    f = ('feature_selection', SelectKBest(score_func = chi2, k = 6))\n",
    "    g = ('model', model)\n",
    "\n",
    "    bundled_pipeline = imbpipeline(steps = [c, d, e, f, g])\n",
    "\n",
    "    return bundled_pipeline\n",
    "\n",
    "##################\n",
    "# Model Selection#\n",
    "##################\n",
    "\n",
    "\n",
    "print(\"Step 10: select_model fcuntion created done successfully\")\n",
    "\n",
    "\n",
    "def select_model(X, y, pipeline=None):\n",
    "\n",
    "    classifiers = {}\n",
    "    \n",
    "\n",
    "    c_d4 = {\"RandomForestClassifier\": RandomForestClassifier()}\n",
    "    classifiers.update(c_d4)\n",
    "\n",
    "    c_d5 = {\"DecisionTreeClassifier\": DecisionTreeClassifier()}\n",
    "    classifiers.update(c_d5)\n",
    "\n",
    "    c_d9 = {\"KNeighborsClassifier\": KNeighborsClassifier()}\n",
    "    classifiers.update(c_d9)\n",
    "\n",
    "    c_d10 = {\"RidgeClassifier\": RidgeClassifier()}\n",
    "    classifiers.update(c_d10)\n",
    "\n",
    "    c_d13 = {\"BernoulliNB\": BernoulliNB()}\n",
    "    classifiers.update(c_d13)\n",
    "\n",
    "    c_d14 = {\"SVC\": SVC()}\n",
    "    classifiers.update(c_d14)\n",
    "   \n",
    "    cols = ['model', 'run_time', 'roc_auc']\n",
    "    df_models = pd.DataFrame(columns = cols)\n",
    "\n",
    "    for key in classifiers:\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        print()\n",
    "        print(\"Step 12: model_pipeline run successfully on\", key)\n",
    "\n",
    "        pipeline = model_pipeline(X_train, classifiers[key])\n",
    "        \n",
    "        cv = cross_val_score(pipeline, X, y, cv=10, scoring='roc_auc')\n",
    "\n",
    "        row = {'model': key,\n",
    "               'run_time': format(round((time.time() - start_time)/60,2)),\n",
    "               'roc_auc': cv.mean(),\n",
    "        }\n",
    "\n",
    "        df_models = pd.concat([df_models, pd.DataFrame([row])], ignore_index=True)\n",
    "        \n",
    "    df_models = df_models.sort_values(by='roc_auc', ascending=False)\n",
    "\t\n",
    "    return df_models\n",
    "    \n",
    "\n",
    "#####################################\n",
    "# Access Model select_model function#\n",
    "#####################################\n",
    "\n",
    "print(\"Step 11: Accessing select_model function done successfully\")\n",
    "\n",
    "\n",
    "models = select_model(X_train, y_train)\n",
    "\n",
    "\n",
    "###################################\n",
    "# Lets see total model with score #\n",
    "###################################\n",
    "\n",
    "print(\"Step 13: Accessing select_model function done successfully\")\n",
    "\n",
    "print(models)\n",
    "\n",
    "#####################################\n",
    "# Accessing best model and training #\n",
    "#####################################\n",
    "\n",
    "print(\"Step 14: Accessing select_model function done successfully\")\n",
    "\n",
    "selected_model = SVC()\n",
    "bundled_pipeline = model_pipeline(X_train, selected_model)\n",
    "bundled_pipeline.fit(X_train, y_train)\n",
    "\n",
    "#####################################\n",
    "# Accessing best model and training #\n",
    "#####################################\n",
    "\n",
    "print(\"Step 15: Results predicted successfully\")\n",
    "y_pred = bundled_pipeline.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "#####################\n",
    "# ROC and AOC score #\n",
    "#####################\n",
    "\n",
    "print(\"Step 16: ROC and AOC scores\")\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1_score = f1_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "p;;rint('ROC/AUC:', roc_auc)\n",
    "print('Accuracy:', accuracy)\n",
    "print('F1 score:', f1_score)\n",
    "\n",
    "\n",
    "\n",
    "#########################\n",
    "# Classification report #\n",
    "#########################\n",
    "\n",
    "print(\"Step 17: classification report generated successfully\")\n",
    "\n",
    "classif_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(classif_report)\n",
    "\n",
    "########################################\n",
    "# BOSS its a right time to celebrate :)#\n",
    "########################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6526091d-17df-4b98-96c7-8b282dc4c485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\prasad shree\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\prasad shree\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imblearn) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\prasad shree\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\prasad shree\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\prasad shree\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\prasad shree\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\prasad shree\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from imbalanced-learn->imblearn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a6a3700-34ed-47b7-ba9b-2940a3ca857c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\prasad shree\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\prasad shree\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.25.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\prasad shree\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.11.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb03f83a-8c0a-4084-b454-30d56889c997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8669910786699108\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming 'X' is your feature matrix and 'y' is your target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15404ea9-fd84-4990-914b-903c31b7c0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Required librarie imported successfully\n",
      "Step 2: Created DataFrame successfully\n",
      "   Administrative  Administrative_Duration  Informational  \\\n",
      "0               0                      0.0              0   \n",
      "1               0                      0.0              0   \n",
      "2               0                      0.0              0   \n",
      "3               0                      0.0              0   \n",
      "4               0                      0.0              0   \n",
      "\n",
      "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
      "0                     0.0               1                 0.000000   \n",
      "1                     0.0               2                64.000000   \n",
      "2                     0.0               1                 0.000000   \n",
      "3                     0.0               2                 2.666667   \n",
      "4                     0.0              10               627.500000   \n",
      "\n",
      "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
      "0         0.20       0.20         0.0         0.0   Feb                 1   \n",
      "1         0.00       0.10         0.0         0.0   Feb                 2   \n",
      "2         0.20       0.20         0.0         0.0   Feb                 4   \n",
      "3         0.05       0.14         0.0         0.0   Feb                 3   \n",
      "4         0.02       0.05         0.0         0.0   Feb                 3   \n",
      "\n",
      "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
      "0        1       1            1  Returning_Visitor    False    False  \n",
      "1        2       1            2  Returning_Visitor    False    False  \n",
      "2        1       9            3  Returning_Visitor    False    False  \n",
      "3        2       2            4  Returning_Visitor    False    False  \n",
      "4        3       1            4  Returning_Visitor     True    False  \n",
      "Step 3: Feature Engineering Done successfully on Weekend, Revenue\n",
      "Step 4: Added Returning_Visitor column successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 1: Required librarie imported successfully\")\n",
    "\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "\n",
    "####################\n",
    "# To ignore warning#\n",
    "####################\n",
    "\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# Loading online_shoppers_intention.csv dataset#\n",
    "################################################\n",
    "\n",
    "print(\"Step 2: Created DataFrame successfully\")\n",
    "\n",
    "df = pd.read_csv(\"A:/Csv_files/online_shoppers_intention/online_shoppers_intention.csv\")\n",
    "\n",
    "print(df.head())\n",
    "#print(df.info())\n",
    "#print(df.describe())\n",
    "\n",
    "\n",
    "######################\n",
    "# Feature Engineering#\n",
    "######################\n",
    "\n",
    "print(\"Step 3: Feature Engineering Done successfully on Weekend, Revenue\")\n",
    "\n",
    "df['Weekend'] = df['Weekend'].replace((True, False), (1, 0))\n",
    "df['Revenue'] = df['Revenue'].replace((True, False), (1, 0))\n",
    "\n",
    "condition = df['VisitorType']=='Returning_Visitor'\n",
    "\n",
    "\n",
    "#################################\n",
    "# Added Returning_Visitor column#\n",
    "#################################\n",
    "\n",
    "print(\"Step 4: Added Returning_Visitor column successfully\")\n",
    "\n",
    "df['Returning_Visitor'] = np.where(condition, 1, 0)\n",
    "\n",
    "df = df.drop(columns=['VisitorType'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cf4841f-77db-4259-b1cd-3713b7a0b774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prasad Shree\\AppData\\Local\\Temp\\ipykernel_1160\\2716292508.py:5: DtypeWarning: Columns (1,2,3,7,8,9,11,12,13,14,17,18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv('A:/Csv_files/Pakistan_dataset/Pakistan Largest Ecommerce Dataset.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 25              1048575\n",
       "Unnamed: 24              1048575\n",
       "Unnamed: 23              1048575\n",
       "Unnamed: 22              1048575\n",
       "Unnamed: 21              1048575\n",
       "sales_commission_code     601229\n",
       "category_name_1           464215\n",
       "sku                       464071\n",
       "status                    464066\n",
       "Customer ID               464062\n",
       "Customer Since            464062\n",
       "Year                      464051\n",
       "FY                        464051\n",
       "M-Y                       464051\n",
       "Month                     464051\n",
       "item_id                   464051\n",
       " MV                       464051\n",
       "Working Date              464051\n",
       "payment_method            464051\n",
       "discount_amount           464051\n",
       "increment_id              464051\n",
       "grand_total               464051\n",
       "qty_ordered               464051\n",
       "price                     464051\n",
       "created_at                464051\n",
       "BI Status                 464051\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "df=pd.read_csv('A:/Csv_files/Pakistan_dataset/Pakistan Largest Ecommerce Dataset.csv')\n",
    "#print(patal_lok)\n",
    "#df.head()\n",
    "#df[df['Customer ID']==33.0]\n",
    "#df.info()\n",
    "#df.shape\n",
    "df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32306a45-0717-4b4c-8a38-7807efe9c357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 25              100.000000\n",
       "Unnamed: 24              100.000000\n",
       "Unnamed: 23              100.000000\n",
       "Unnamed: 22              100.000000\n",
       "Unnamed: 21              100.000000\n",
       "sales_commission_code     57.337720\n",
       "category_name_1           44.271034\n",
       "sku                       44.257302\n",
       "status                    44.256825\n",
       "Customer ID               44.256443\n",
       "Customer Since            44.256443\n",
       "Year                      44.255394\n",
       "FY                        44.255394\n",
       "M-Y                       44.255394\n",
       "Month                     44.255394\n",
       "item_id                   44.255394\n",
       " MV                       44.255394\n",
       "Working Date              44.255394\n",
       "payment_method            44.255394\n",
       "discount_amount           44.255394\n",
       "increment_id              44.255394\n",
       "grand_total               44.255394\n",
       "qty_ordered               44.255394\n",
       "price                     44.255394\n",
       "created_at                44.255394\n",
       "BI Status                 44.255394\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.isna().mean()*100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c6dc8d6-9e15-48d0-a42d-fe506be0795c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>BI Status</th>\n",
       "      <th>Gross</th>\n",
       "      <th>Net</th>\n",
       "      <th>Valid</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>canceled</th>\n",
       "      <td>59806</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>closed</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cod</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1128</td>\n",
       "      <td>1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complete</th>\n",
       "      <td>0</td>\n",
       "      <td>28307</td>\n",
       "      <td>0</td>\n",
       "      <td>28307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holded</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_refunded</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11347</td>\n",
       "      <td>11347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paid</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>502</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_review</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pending</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>processing</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>received</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34188</td>\n",
       "      <td>34188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refund</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1676</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>59932</td>\n",
       "      <td>28390</td>\n",
       "      <td>48841</td>\n",
       "      <td>137163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "BI Status       Gross    Net  Valid     All\n",
       "status                                     \n",
       "canceled        59806      0      0   59806\n",
       "closed              0     83      0      83\n",
       "cod                 0      0   1128    1128\n",
       "complete            0  28307      0   28307\n",
       "holded             25      0      0      25\n",
       "order_refunded      0      0  11347   11347\n",
       "paid                0      0    502     502\n",
       "payment_review     31      0      0      31\n",
       "pending            39      0      0      39\n",
       "processing         31      0      0      31\n",
       "received            0      0  34188   34188\n",
       "refund              0      0   1676    1676\n",
       "All             59932  28390  48841  137163"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index=df[df['sales_commission_code'].isna()]['status'],columns=df[df['sales_commission_code'].isna()]['BI Status'],margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47acc4a0-d661-4519-a8a4-0ac86a5ff461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category_name_1'].fillna(df['category_name_1'].mode()[0],inplace=True)\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2bc51c0-ae8f-42e0-9c00-19b2d71d52a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sku'].fillna(\"Missing\",inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06bee378-29d1-430c-a6ba-13c1f0c0ac2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (2205153000.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    1.Display Top 10 Rows of the Dataset\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "#Ecommerce purchase project\n",
    "1.Display Top 10 Rows of the Dataset\n",
    "data.head(10)\n",
    "\n",
    "2.check last 10 rows of the dataset\n",
    "data.tail(10)\n",
    "\n",
    "3.check datatype of each column\n",
    "data.dtypes\n",
    "\n",
    "4.check Null values in dataset\n",
    "data.isnull().sum()\n",
    "\n",
    "5.How many Rows and Columns are there in our dataset\n",
    "len(data.columns)\n",
    "len(data)\n",
    "data.info()\n",
    "\n",
    "6.Highest and lowest purchase prices\n",
    "data.columns\n",
    "data['Purchase Price'].max()\n",
    "data['Purchase Price'].min()\n",
    "\n",
    "7.Average Purchase Price\n",
    "data['Purchase Price'].mean()\n",
    "\n",
    "8.How many people Have French \"fr\" as their language?\n",
    "data[data['language']==\"fr\"]\n",
    "len(data[data['language']==\"fr\"])\n",
    "data[data['language']==\"fr\"].count()\n",
    "\n",
    "9.job Title Contains Engineer\n",
    "len(data[data['job'].str.contains('engineer',case=False)])\n",
    "\n",
    "10.Find Email of the persion with the following IP address:132.207.160.22\n",
    "data[data['IP Address']==\"132.207.160.22\"]['Email']\n",
    "\n",
    "len(data[(data['CC Provider']==\"Mastercard\") & data ['Purchase Price']>50)])  00r0r0r\n",
    "data[(data['CC Provider']==\"Mastercard\") & (data ['Purchase Price']>50)].count()\n",
    "\n",
    "12.Find Email of the persion with the following credit card number: 4664825258997302\n",
    "data.columns\n",
    "data[data['credit card']==\"4664825258997302\"]['Email']\n",
    "\n",
    "13.How many people purchase during the AM and How many people purchase during pm\n",
    "data.columns\n",
    "data['AM or PM'].value_counts()\n",
    "\n",
    "14.how many people have credit card thet expire in 2020\n",
    "data.columns\n",
    "len(data[data['CC Exp Date'].apply(lamda x:x[3:]=='20')])\n",
    "or\n",
    "def fun():\n",
    "    count=0\n",
    "    for date in data['CC Exp Date']:\n",
    "        if date.split('/')[1]=='20':\n",
    "            count=count+1\n",
    "    \n",
    "    print(count)    \n",
    "fun()        \n",
    "\n",
    "15. Top 5 Most Popular Email providers(eg.gmail.com,yahoo.com,etc)\n",
    "list1=[]\n",
    "for email in data['Email']:\n",
    "    list1.append(email.split('@')[1])\n",
    "data['temp']=list1\n",
    "data.head(1)\n",
    "data['temp'].value_counts().head()\n",
    "#orrrrr\n",
    "data['Email'].apply(lambda X:X.split('@')[1]).value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3095f3be-137c-4b61-8c62-ead34d407134",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m             count\u001b[38;5;241m=\u001b[39mcount\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(count)    \n\u001b[1;32m----> 8\u001b[0m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m        \n",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m, in \u001b[0;36mfun\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun\u001b[39m():\n\u001b[0;32m      2\u001b[0m     count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCC Exp Date\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m date\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m20\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      5\u001b[0m             count\u001b[38;5;241m=\u001b[39mcount\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "def fun():\n",
    "    count=0\n",
    "    for date in data['CC Exp Date']:\n",
    "        if date.split('/')[1]=='20':\n",
    "            count=count+1\n",
    "    \n",
    "    print(count)    \n",
    "fun()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac951867-ccec-4f06-8120-c96d618cf483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('salaries.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
